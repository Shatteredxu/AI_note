# 深度学习基础
## 线性回归从零开始实现
### 线性回归基本要素
1. 模型：输入输出是线性关系
2. 训练：找到一组最好的参数值
3. 数据：输入和输出的对应值
4. 损失函数：通过最小化损失函数来找到一组最好的参数值，常用MSE均方误差
5. 优化算法：寻找最优参数值的算法，常用梯度下降算法—>小批量梯度下降（先选取⼀组模型参数的初始值，如随机选取；接下来对
参数进⾏多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样⼀个由固定数⽬训练数据样本所组成的小批量（mini-batch）B，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后⽤此结果与预先设定的⼀个正数的乘积作为模型参数在本次迭代的减小量。）
6. 模型预测：得到优化算法所计算出来的参数，用训练出来的模型来预测
### 线性回归的表示方法
1.神经网络图：

```
* 线性回归是⼀个单层神经⽹络。输出层中负责计算o的单元⼜叫神经元。
* 在线性回归中，o的计算依赖于x1 和x2。也就是说，输出层中的神经元和输⼊层中各个输⼊完全连接。因此，这⾥的输出层⼜叫全连接层（fully-connected layer）或稠密层（dense layer）
```
### 矢量计算表达式
矢量计算机方法主要有两种

```
* 第一种：对应数组中的值逐个相加，
* 第二种：直接相加
```
后者性能优于前者
### 线性回归从头实现
1.生成数据集
![image](http://qcihljxys.bkt.clouddn.com/1593157901%281%29.png)
2.用matplot查看一下数据集的分布（pyplot应用）
```
def use_svg_display():
    display.set_matplotlib_formats('svg')
def set_figsize(figsize=(3.5, 2.5)):
    use_svg_display()
    # 设置图的尺⼨
    plt.rcParams['figure.figsize'] = figsize
    set_figsize()
    plt.scatter(features[:, 1].asnumpy(), labels.asnumpy(), 1);
```
3.读取数据

```python
def data_iter(batch_size,features,labels):
    num_examples=len(features)
    indices = list(range(num_examples))
    random.shuffle(indices)
    for i in range(0,num_examples,batch_size):
        j = nd.array(indices[i: min(i + batch_size, num_examples)])
        yield features.take(j), labels.take(j) # take函数根据索引返回
```
新建tools文件，data_iter方进去，通过from tools import data_iter导入, 调用 

```python
batch_size=10;# 需要查看多少个数据
for X, y in data_iter(batch_size, features, labels):
    print(X, y)
    break
```
4.初始化模型参数
```python
# 初始化w,b参数
 w = nd.random.normal(scale=0.01, shape=(num_inputs, 1))#num_inputs为2，分别创建2维的w矩阵
 b = nd.zeros(shape=(1,))
 #分别创建他们的梯度
 w.attach_grad()
b.attach_grad()
```
5.定义模型
```
def linreg(X, w, b): # 本函数已保存在tools文件中直接调用
    return nd.dot(X, w) + b
```
6.定义损失函数

```math
MSE=(y-y*)^2/2
```

```python
def squared_loss(y_hat, y): # 本函数已保存在tools文件中直接调用
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2
    # y_hat表示预测值，y表示真实值
```
7.定义优化算法

```python
def sgd(params, lr, batch_size):  # 本函数已保存在tools文件中直接调用
    for param in params:
        param.data -= lr * param.grad / batch_size # 注意这里更改param时用的param.dat
```
lr代表学习率， param.grad代表自动求导，利用循环来更新每一个参数值  

8.训练模型
- 读取的小批量数据样本（特
征X和标签y）
- 调⽤反向函数backward计算小批量随机梯度，并调⽤优化算法sgd迭代模型参数

```python
lr = 0.03
num_epochs = 3
net = linreg
loss = squared_loss
for epoch in range(num_epochs): # 训练模型⼀共需要num_epochs个迭代周期
# 在每⼀个迭代周期中，会使⽤训练数据集中所有样本⼀次（假设样本数能够被批量⼤⼩整除）。X
# 和y分别是⼩批量样本的特征和标签
for X, y in data_iter(batch_size, features, labels):
    with autograd.record():
        l = loss(net(X, w, b), y) #l是有关⼩批量X和y的损失
    l.backward() # ⼩批量的损失对模型参数求梯度
    sgd([w, b], lr, batch_size) # 使⽤⼩批量随机梯度下降迭代模型参数
train_l = loss(net(features, w, b), labels)
print('epoch %d, loss %f' % (epoch + 1, train_l.mean().asnumpy()))
```
#### 全部代码
```
from IPython import display
from matplotlib import pyplot as plt
from mxnet import autograd,nd
import random
from tools import data_iter,squared_loss,linreg,sgd
#生成数据集
num_inputs = 2
num_examples = 1000
true_w = [2, -3.4]
true_b = 4.2
#生成x
features = nd.random.normal(scale=1, shape=(num_examples, num_inputs))
# 生成y=w1x1+w2x2+b
labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b
# 添加噪声
labels += nd.random.normal(scale=0.01, shape=labels.shape)
def use_svg_display():
    display.set_matplotlib_formats('svg')
def set_figsize(figsize=(3.5, 2.5)):
    use_svg_display()
    # 设置图的尺⼨
    plt.rcParams['figure.figsize'] = figsize

set_figsize()
plt.scatter(features[:, 1].asnumpy(), labels.asnumpy(), 1); # 加分号只显⽰图

w = nd.random.normal(scale=0.01, shape=(num_inputs, 1))#num_inputs为2，分别创建2维的w矩阵
b = nd.zeros(shape=(1,))
#分别创建他们的梯度
w.attach_grad()
b.attach_grad()
lr = 0.03
num_epochs = 3
net = linreg
loss = squared_loss
batch_size = 10

for epoch in range(num_epochs):

    for X, y in data_iter(batch_size, features, labels):
        with autograd.record():
            l = loss(net(X, w, b), y) #l是有关⼩批量X和y的损失
        l.backward() # ⼩批量的损失对模型参数求梯度
        sgd([w, b], lr, batch_size) # 使⽤⼩批量随机梯度下降迭代模型参数
    train_l = loss(net(features, w, b), labels)
    print('epoch %d, loss %f' % (epoch + 1, train_l.mean().asnumpy()))
print(true_w,w,true_b,b)
```
#### 练习(todo)
- 为什么squared_loss函数中需要使⽤reshape函数？
- 尝试使⽤不同的学习率，观察损失函数值的下降快慢。
-  如果样本个数不能被批量⼤小整除，data_iter函数的⾏为会有什么变化？
## 线性回归的简单实现
1. 生成数据集(同上一节)
```
num_inputs = 2
num_examples = 1000
true_w = [2, -3.4]
true_b = 4.2
features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float)
labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b
labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)
```

2. 读取数据  

```
PyTorch提供了data包来读取数据。由于data常用作变量名，我们将导入的data模块用Data代替。
```
在每一次迭代中，我们将随机读取包含10个数据样本的小批量。
```python
import torch.utils.data as Data
batch_size = 10
# 将训练数据的特征和标签组合
dataset = Data.TensorDataset(features, labels)
# 随机读取小批量
data_iter = Data.DataLoader(dataset, batch_size, shuffle=True)
```
测试一下

```
for X, y in data_iter:
    print(X, y)
    break
```
3. 定义模型
这节代码将会更加简洁，首先导入
```torch.nn```模块该模块定义了大量神经网络的层。

```
# 3.模型定义
# 继承nn.Module，重写自己的网络
#可以用nn.Sequential来更加方便地搭建网络，Sequential是一个有序的容器，网络层将按照在传入Sequential的顺序依次被添加到计算图中。
import torch.nn as nn
net = nn.Sequential(
    nn.Linear(num_inputs, 1)
    # 此处还可以传入其他层
    )
#测试编写的网络结构，输入训练数据
print(net[0]) # 使用print可以打印出网络的结构
```
4. 初始化模型参数

```python
from torch.nn import init

init.normal_(net[0].weight, mean=0, std=0.01)
#init.normal_将权重参数每个元素初始化为随机采样于均值为0、标准差为0.01的正态分布。偏差会初始化为零。
init.constant_(net[0].bias, val=0)  
# 用值val填充向量bias
```
5. 定义损失函数

```
loss = nn.MSELoss()
```

6. 定义优化算法
 ```
import torch.optim as optim

optimizer = optim.SGD(net.parameters(), lr=0.03)
#学习率0.03，net.parameters()初始化参数，采用SGD优化算法
print(optimizer)
```
如果动态学习率怎么弄？

```
# 调整学习率
for param_group in optimizer.param_groups:
    param_group['lr'] *= 0.1 # 学习率为之前的0.1倍
```

7. 训练模型

```
# 7.开始训练
num_epochs = 3
for epoch in range(1,num_epochs+1):
    for X,y in data_iter:
        output = net(X)
        l = loss(output,y.view(-1,1))
        optimizer.zero_grad()
        l.backward()
        optimizer.step()
    print('epoch %d, loss: %f' % (epoch, l.item()))
# 8.打印参数
dense = net[0]
print(true_w, dense.weight)
print(true_b, dense.bias)
```
8. 全部代码总结

```python
import torch
from IPython import display
from matplotlib import pyplot as plt
import numpy as np
import random


# 1.生成数据集
num_inputs = 2
num_examples = 1000
true_w = [2, -3.4]
true_b = 4.2
features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float)
labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b
labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)


#2.读取数据
import torch.utils.data as Data
batch_size = 10
# 将训练数据的特征和标签组合
dataset = Data.TensorDataset(features, labels)
# 随机读取小批量
data_iter = Data.DataLoader(dataset, batch_size, shuffle=True)


# 3.模型定义
# 继承nn.Module，重写自己的网络
#可以用nn.Sequential来更加方便地搭建网络，Sequential是一个有序的容器，网络层将按照在传入Sequential的顺序依次被添加到计算图中。
import torch.nn as nn
net = nn.Sequential(
    nn.Linear(num_inputs, 1)
    # 此处还可以传入其他层
    )
#测试编写的网络结构，输入训练数据
print(net[0]) # 使用print可以打印出网络的结构


# 4.使用init库初始化模型参数
from torch.nn import init
init.normal_(net[0].weight,mean=0,std=0.01)
init.constant_(net[0].bias,val=0)


# 5.定义损失函数MSE
loss = nn.MSELoss()


# 6.定义优化算法
import torch.optim as optim
optimizer = optim.SGD(net.parameters(), lr=0.03)
print(optimizer)


# 7.开始训练
num_epochs = 3
for epoch in range(1,num_epochs+1):
    for X,y in data_iter:
        output = net(X)
        l = loss(output,y.view(-1,1))#view效果通reshape，就是改变y的形状
        optimizer.zero_grad()#梯度清零
        l.backward()#反向传播
        optimizer.step()#迭代更新参数
    print('epoch %d, loss: %f' % (epoch, l.item()))
    

# 8.打印参数
dense = net[0]
print(true_w, dense.weight)
print(true_b, dense.bias)
```
## softmax回归
引入softmax主要用于输出为离散值的分类问题，前几节的回归模型适用于输出为连续值的情景
### softmax模型
就是将输出的离散值，归入一个区间中，他们所有的相加得1，也就是概率
- [ ] ###  交叉熵损失函数(有神马用处)
```math
y_i= {exp(o_1)\over \sum_{i=0}^n exp(o_i)}
```
- softmax回归适用于分类问题。它使用softmax运算输出类别的概率分布。
- softmax回归是一个单层神经网络，输出个数等于分类问题中的类别个数。
- 交叉熵适合衡量两个概率分布的差异。

## 图像分类数据集（Fashion-MNIST）
后面的数据集用一个图像内容更加复杂的数据集Fashion-MNIST[2]（这个数据集也比较小，只有几十M，没有GPU的电脑也能吃得消）  

本节我们将使用```torchvision```
包，它是服务于PyTorch深度学习框架的，主要用来构建计算机视觉模型。torchvision主要由以下几部分构成：
1. ```torchvision.datasets```:一些加载数据的函数及常用的数据集接口；
2. ```torchvision.models```: 包含常用的模型结构（含预训练模型），例如AlexNet、VGG、ResNet等；
3. ```torchvision.transforms```: 常用的图片变换，例如裁剪、旋转等；
4.  ```torchvision.utils```: 其他的一些有用的方法
### 获取数据集
1. 导入所需要的包
```
import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import time
import sys
sys.path.append("..") # 为了导入上层目录的d2lzh_pytorch
import d2lzh_pytorch as d2l
```
2.下载数据集
第一次会花费较长时间去下载
```python
mnist_train = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=True, download=True, transform=transforms.ToTensor())
mnist_test = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=False, download=True, transform=transforms.ToTensor())
print(type(mnist_train))#<class 'torchvision.datasets.mnist.FashionMNIST'>
print(len(mnist_train), len(mnist_test))#打印数据集训练样本有60000，测试样本有10000
feature, label = mnist_train[0]#获取第一个样本数据
print(feature.shape, label)#打印的是1X28X28的CxHxW

```
![image](http://qcihljxys.bkt.clouddn.com/1593224327%281%29.png)
下载完成后面可以通过```show_fashion_mnist```方法调用一次显示10张图片，代码如下

```python
X, y = [], []
for i in range(10):
    X.append(mnist_train[i][0])#X代表训练数据集的feature标签
    y.append(mnist_train[i][1])#y代表训练数据集的label标签
show_fashion_mnist(X, get_fashion_mnist_labels(y))
```python
3.利用pytorh读取部分数据
在使用时，利用```torch.utils.data.DataLoader```中的方法来小批量读取一部分数据，在实践中，数据读取经常是训练的性能瓶颈，特别当模型较简单或者计算硬件性能较高时。PyTorch的**DataLoader**中一个很方便的功能是允许使用**多进程**来加速数据读取。这里我们通过参数num_workers来设置4个进程读取数据
```# 利用dataloader读取小批量数据
batch_size = 256#一次放入256个数据
if sys.platform.startswith("win"):
    num_workers = 0
else:
    num_workers = 4
train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)
test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)
    # shuffle=true代表随机选取
start = time.time()
for X, y in train_iter:
    continue
print('%.2f sec' % (time.time() - start))#结果：8.83 sec
```
## softmax回归的从零开始实现
1. 获取和导入数据
```
import torch
import torchvision
import numpy as np
import sys
from getDatasets import load_data_fashion_mnist
# 1. 获取数据
batch_size = 256
train_iter,test_iter =load_data_fashion_mnist(batch_size)
```
2. 初始化模型参数
> 每个样本输入是高和宽均为28像素的图像。模型的输入向量的长度是```28×28=784```：该向量的每个元素对应图像中每个像素。由于图像有10个类别，单层神经网络输出层的输出个数为10，因此softmax回归的权重和偏差参数分别为784×10和1×10的矩阵
- [ ] requires_grad_的作用
```python
num_inputs = 784
num_outputs = 10
#随机生成初始化参数w,b
W = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_outputs)), dtype=torch.float)
b = torch.zeros(num_outputs, dtype=torch.float)

W.requires_grad_(requires_grad=True)
b.requires_grad_(requires_grad=True)
# requires_grad_()的主要用途是告诉自动求导开始记录对Tensor的操作。
```
3. 实现softmax运算
sum函数的使用：传入dim=i维度，i=0，代表列维度相加；i=1代表行维度相加

```python
def softmax(x):
    X_exp = x.exp()
    partition = X_exp.sum(dim=1,keepdim=True)
    return X_exp/partition
X = torch.rand((2,5)) #生成2X5的矩阵，从区间[0, 1)的均匀分布中抽取的一组随机数
# randn 返回一个张量，包含了从标准正态分布（均值为0，方差为1，即高斯白噪声）中抽取的一组随机数。张量的形状由参数sizes定义。
X_prob=softmax(X)
print(X_prob,"----",X_prob.sum(dim=1))

```
4. 定义模型
- ```torch.mul(a, b)```是矩阵a和b对应位相乘，a和b的维度必须相等，比如a的维度是(1, 2)，b的维度是(1, 2)，返回的仍是(1, 2)的矩阵
- ```torch.mm(a, b)```是矩阵a和b矩阵相乘，比如a的维度是(1, 2)，b的维度是(2, 3)，返回的就是(1, 3)的矩阵

所以mm方法的作用就是将w与x相乘+b，侯建y=wx+b的模型
view方法同numpy中的reshape，改变矩阵的形状

```python
def net(X):
    return softmax(torch.mm(X.view((-1, num_inputs)), W) + b)
```
5. 损失函数的定义
- [ ] gather函数的使用

```python
def cross_entropy(y_hat, y):
    return - torch.log(y_hat.gather(1, y.view(-1, 1)))
```
6. 计算分类准确率

```python
def accuracy(y_hat, y):
    return (y_hat.argmax(dim=1) == y).float().mean().item()
```
7.训练模型

```
num_epochs, lr = 5, 0.1

# 本函数已保存在d2lzh包中方便以后使用
def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,
              params=None, lr=None, optimizer=None):
    for epoch in range(num_epochs):
        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0
        for X, y in train_iter:
            y_hat = net(X)
            l = loss(y_hat, y).sum()

            # 梯度清零
            if optimizer is not None:
                optimizer.zero_grad()
            elif params is not None and params[0].grad is not None:
                for param in params:
                    param.grad.data.zero_()

            l.backward()
            if optimizer is None:
                d2l.sgd(params, lr, batch_size)
            else:
                optimizer.step()  # “softmax回归的简洁实现”一节将用到


            train_l_sum += l.item()
            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()
            n += y.shape[0]
        test_acc = evaluate_accuracy(test_iter, net)
        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'
              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))

train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)

```

8.预测结果

```
#8.训练结束后进行结果预测
X, y = iter(test_iter).next()

true_labels = get_fashion_mnist_labels(y.numpy())
pred_labels = get_fashion_mnist_labels(net(X).argmax(dim=1).numpy())
titles = [true + '\n' + pred for true, pred in zip(true_labels, pred_labels)]

show_fashion_mnist(X[0:9], titles[0:9])
```
9.总结代码

```python
# TODO 未完成
import torch
import torchvision
import numpy as np
import sys
from getDatasets import load_data_fashion_mnist
from tools import evaluate_accuracy,sgd,get_fashion_mnist_labels,show_fashion_mnist
# 1.获取数据
batch_size = 256
train_iter,test_iter =load_data_fashion_mnist(batch_size)

# 2.初始化模型参数
num_inputs = 784
num_outputs = 10
#随机生成初始化参数w,b
W = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_outputs)), dtype=torch.float)
b = torch.zeros(num_outputs, dtype=torch.float)

W.requires_grad_(requires_grad=True)
b.requires_grad_(requires_grad=True)#注意这里是false
# requires_grad_()的主要用途是告诉自动求导开始记录对Tensor的操作。

# 3.实现softmax运算
def softmax(x):
    X_exp = x.exp()
    partition = X_exp.sum(dim=1,keepdim=True)
    return X_exp/partition
# 下面几行代码主要是为了测试softmax函数
X = torch.rand((2,5)) #生成2X5的矩阵，从区间[0, 1)的均匀分布中抽取的一组随机数
# randn 返回一个张量，包含了从标准正态分布（均值为0，方差为1，即高斯白噪声）中抽取的一组随机数。张量的形状由参数sizes定义。
X_prob=softmax(X)
print(X_prob,"////",X_prob.sum(dim=1))


# 5. 定义基本模型（注意mm函数的使用）
def net(X):
    return softmax(torch.mm(X.view((-1, num_inputs)), W) + b)


#6. 定义损失函数，这里使用的是交叉熵损失函数
def cross_entropy(y_hat, y):
    return - torch.log(y_hat.gather(1, y.view(-1, 1)))
# print(evaluate_accuracy(test_iter, net))测试


# 7.训练模型
num_epochs,lr = 5,0.1
def train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params=None,lr=None,optimizer=None):
    for epoch in range(num_epochs):  # 一次性读取的数据量
        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0
        for X, y in train_iter:
            y_hat = net(X)
            l = loss(y_hat, y).sum()  # 计算损失

            # 梯度清零
            if optimizer is not None:
                optimizer.zero_grad()
            elif params is not None and params[0].grad is not None:
                for param in params:
                    param.grad.data.zero_()

            l.backward()
            if optimizer is None:
                sgd(params, lr, batch_size)
            else:
                optimizer.step()  # 实现参数自动更新

            train_l_sum += l.item()# item是得到一个元素张量里面的元素值
            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()
            n += y.shape[0]
        # 计算分类准确度
        test_acc = evaluate_accuracy(test_iter, net)
        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'
              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))


train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)
#8.训练结束后进行结果预测
X, y = iter(test_iter).next()

true_labels = get_fashion_mnist_labels(y.numpy())
pred_labels = get_fashion_mnist_labels(net(X).argmax(dim=1).numpy())
titles = [true + '\n' + pred for true, pred in zip(true_labels, pred_labels)]

show_fashion_mnist(X[0:9], titles[0:9])
```
##  softmax回归的简洁实现

### softmax和交叉熵损失函数
这一节与线性回归的区别在于定义的交叉熵损失函数，CrossEntropyLoss将softmax和交叉熵损失函数结合在一起，**数值稳定性更好**，在线性回归中我们使用的是**最小化MSE损失函数**，来获得最优解，本节使用**交叉熵损失函数**，

```
# 3.softmax和交叉熵损失函数
loss = nn.CrossEntropyLoss()
```
### 代码小结

```
import torch
from torch import nn
from torch.nn import init
import numpy as np
import sys
from getDatasets import load_data_fashion_mnist
from tools import evaluate_accuracy,sgd,get_fashion_mnist_labels,show_fashion_mnist,FlattenLayer,train_ch3
# 1.获取数据
batch_size = 256
train_iter,test_iter =load_data_fashion_mnist(batch_size)

# 2.初始化模型
num_inputs = 784
num_outputs = 10
#定义一个线性模型
class LinearNet(nn.Module):
    def __init__(self, num_inputs, num_outputs):
        super(LinearNet, self).__init__()
        self.linear = nn.Linear(num_inputs, num_outputs)
    def forward(self, x): # x shape: (batch, 1, 28, 28)
        y = self.linear(x.view(x.shape[0], -1))
        return y

net = LinearNet(num_inputs, num_outputs)
# 定义网络结构，将两个模型组合为一个网络
from collections import OrderedDict
net = nn.Sequential(
    OrderedDict([
        ('flatten',FlattenLayer()),
        ('linear',nn.Linear(num_inputs,num_outputs))
    ])
)
# 初始化参数
init.normal_(net.linear.weight, mean=0, std=0.01)
init.constant_(net.linear.bias, val=0)

# 3.softmax和交叉熵损失函数
loss = nn.CrossEntropyLoss()

# 4.定义优化算法
optimizer = torch.optim.SGD(net.parameters(), lr=0.1)
# 5.训练模型
num_epochs = 5
train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)
```
## 多层感知机
在之前的线性回归和softmax回归都是单层神经网络。然而深度学习主要关注多层模型。在本节中引入多层感知机（multilayer perceptron，MLP）探索深层神经网络
1. 隐藏层
如图：
输入层输入数据，隐藏层五个节点通过计算到输出层结点，并且多层感知机中的隐藏层和输出层都是**全连接层**。
![image](https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter03/3.8_mlp.svg)
2. 激活函数
激活函数的作用就是为了加入**非线性变换**，因为如果没有激活函数，隐藏层通过线性函数来输出，这样不管有多少层，输出层的节点还是输入层的线性变换，所以加入激活函数能使网络能够更好的拟合数据
主要的激活函数有**RELU函数**，sigmod函数，tanh函数
- RELU函数提供了一个很简单的非线性变换。给定元素x，该函数定义为
```math
RELU(x)=max(x,0)
```
可以看出，ReLU函数只**保留正数元素**，并**将负数元素清零**
- sigmod函数
sigmoid函数可以将元素的值变换到0和1之间：
```math
sigmod(x) = {1\over1+exp(x)}
```
但由于指数运算过于**耗时间**，以及sigmod函数**求导比较麻烦**等原因，现在大多数都采用RELU激活函数
- tanh函数
tanh（双曲正切）函数可以将元素的值变换到-1和1之间：
```math
tanh(x)={1-exp(x)\over1+exp(x)}
```
tanh函数有与sigmod函数一样的缺点，现在很少使用

### 多层感知机
多层感知机就是含有至少一个隐藏层的由全连接层组成的神经网络，且每个隐藏层的输出通过激活函数进行变换。多层感知机的层数和各隐藏层中隐藏单元个数都是超参数

## 多层感知机的从零开始实现
1. 获取数据  
2. 定义模型参数
```python
num_inputs, num_outputs, num_hiddens = 784, 10, 256

W1 = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_hiddens)), dtype=torch.float)
b1 = torch.zeros(num_hiddens, dtype=torch.float)
W2 = torch.tensor(np.random.normal(0, 0.01, (num_hiddens, num_outputs)), dtype=torch.float)
b2 = torch.zeros(num_outputs, dtype=torch.float)

params = [W1, b1, W2, b2]
for param in params:
    param.requires_grad_(requires_grad=True)
```

3. 定义激活函数
```
def relu(X):
    return torch.max(input=X, other=torch.tensor(0.0))
```
4. 定义模型
```
def net(X):
    X = X.view((-1, num_inputs))
    H = relu(torch.matmul(X, W1) + b1)#通过激活函数的输出
    return torch.matmul(H, W2) + b2
```
5.s损失函数
```
loss = torch.nn.CrossEntropyLoss()
```
6. 训练模型
（处理同上一节一样）
## 多层感知机的简洁实现
代码同softmax简洁实现基本相同(大致看看即可)
## 模型选择、欠拟合和过拟合
### 训练误差和泛化误差

```
* 前者指模型在训练数据集上表现出的误差，
* 后者指模型在任意一个测试数据样本上表现出的误差的期望，并常常通过测试数据集上的误差来近似。

```
通俗来讲训练误差就是在训练模型时候得到的准确率，泛化误差就是指模型训练完成后，在测试数据集上的误差
### K折交叉验证
由于验证数据集不参与模型训练，当训练数据不够用时，预留大量的验证数据显得太奢侈。一种改善的方法是[Math Processing Error]K折交叉验证。在K折交叉验证中，我们把原始训练数据集分割成K个不重合的子数据集，然后我们做K次模型训练和验证。每一次，我们使用一个子数据集验证模型，并使用其他K−1个子数据集来训练模型。在这K次训练和验证中，每次用来验证模型的子数据集都不同。最后，我们对这K次训练误差和验证误差分别求平均。
> 这部分的理论性知识，周志华老师的西瓜书上已经很清楚了，这里不做太多陈述
### 欠拟合和过拟合
我们将探究模型训练中经常出现的两类典型问题：一类是模型无法得到较低的训练误差，我们将这一现象称作欠拟合（underfitting）；另一类是模型的训练误差远小于它在测试数据集上的误差，我们称该现象为过拟合（overfitting）。在实践中，我们要尽可能同时应对欠拟合和过拟合。我们重点讨论两个影响复杂度的因素：**模型复杂度**和**训练数据集大**小**。
- 模型复杂度：模型复杂度越高，模型越有可能过拟合，这是由于模型复杂度过高，导致模型记住了每一个训练样本的特征
- 训练数据集大小：影响欠拟合和过拟合的另一个重要因素是训练数据集的大小。一般来说，如果训练数据集中样本数过少，特别是比模型参数数量（按元素计）更少时，过拟合更容易发生。此外，泛化误差不会随训练数据集里样本数量增加而增大。因此，在计算资源允许的范围之内，我们通常希望训练数据集大一些，特别是在模型复杂度较高时，例如层数较多的深度学习模型
<!--### 做个小实验-->
<!--1. 生成数据集-->
<!--首先我们生成如下的三阶多项式函数来生成该样本的标签：-->
<!--```math-->
<!--y=1.2x-3.4x^2+5.6x^3+5+c-->
<!--```-->
<!--其中噪声项ϵϵ服从均值为0、标准差为0.01的正态分布。训练数据集和测试数据集的样本数都设为100。-->

## 权重衰减(*出了问题*)
权重衰减主要用于应对过拟合问题，因为增大训练数据集可能会减轻过拟合，但是获取额外的训练数据往往代价高昂，所以引入**权重衰减**  
权重衰减就等价于机器学习中的L2范数，通过加入惩罚项来减少过拟合
1. 生成数据

```
n_train, n_test, num_inputs = 20, 100, 200
true_w, true_b = torch.ones(num_inputs, 1) * 0.01, 0.05

features = torch.randn((n_train + n_test, num_inputs))
labels = torch.matmul(features, true_w) + true_b
labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)
train_features, test_features = features[:n_train, :], features[n_train:, :]
train_labels, test_labels = labels[:n_train], labels[n_train:]
```
2.初始化模型参数

```
def init_params():
    w = torch.randn((num_inputs, 1), requires_grad=True)
    b = torch.zeros(1, requires_grad=True)
    return [w, b]
```
3. 定义L2范数惩罚项
```
def l2_penalty(w):
    return (w**2).sum() / 2
```
4. 定义训练和测试


```
batch_size, num_epochs, lr = 1, 100, 0.003
net, loss = d2l.linreg, d2l.squared_loss

dataset = torch.utils.data.TensorDataset(train_features, train_labels)
train_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True)

def fit_and_plot(lambd):
    w, b = init_params()
    train_ls, test_ls = [], []
    for _ in range(num_epochs):
        for X, y in train_iter:
            # 添加了L2范数惩罚项
            l = loss(net(X, w, b), y) + lambd * l2_penalty(w)
            l = l.sum()

            if w.grad is not None:
                w.grad.data.zero_()
                b.grad.data.zero_()
            l.backward()
            d2l.sgd([w, b], lr, batch_size)
        train_ls.append(loss(net(train_features, w, b), train_labels).mean().item())
        test_ls.append(loss(net(test_features, w, b), test_labels).mean().item())
    d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'loss',
                 range(1, num_epochs + 1), test_ls, ['train', 'test'])
    print('L2 norm of w:', w.norm().item())
```
5.观察过拟合
```
fit_and_plot(lambd=0)
```
## 丢弃法
解决过拟合的又一个方法：**丢弃法**
丢弃法等价于神经网络中的Dropout层，主要就是在隐藏层节点中随机丢弃一些节点，被丢弃节点参数值在之后不会被更新，这样输出层节点的值就不会依赖任何其中某个节点了

```
# 定义模型参数
drop_prob1, drop_prob2 = 0.2, 0.5
# 丢弃发简洁实现
net = nn.Sequential()
net.add(nn.Dense(256, activation="relu"),
    nn.Dropout(drop_prob1), # 在第⼀个全连接层后添加丢弃层
    nn.Dense(256, activation="relu"),
    nn.Dropout(drop_prob2), # 在第⼆个全连接层后添加丢弃层
    nn.Dense(10))
net.initialize(init.Normal(sigma=0.01))
num_epochs, lr, batch_size = 5, 0.5, 256
loss = gloss.SoftmaxCrossEntropyLoss()
train_iter, test_iter = load_data_fashion_mnist(batch_size)

trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})
train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,
None, trainer)
```
## 正向传播、反向传播和计算图
### 正向传播
正向传播是指对神经⽹络沿着从输⼊层到输出层的顺序，**依次计算并存储模型的中间变量**（包括
输出）
## kaggle练手
1. 下载数据：++https://www.kaggle.com/c/house-prices-advanced-regression-techniques 。++
2.导入数据

```python
train_data = pd.read_csv('C:/Users/Administrator/桌面/house-prices-advanced-regression-techniques/train.csv')
test_data = pd.read_csv('C:/Users/Administrator/桌面/house-prices-advanced-regression-techniques/test.csv')
print(train_data.shape)
# 获取除了第一个特征外的其他特征
all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))
```
3. 预处理数据
连续数值的特征做**标准化**（standardization）：设该特征在整个数据集上的均值为µ，标准
差为σ。那么，我们可以将该特征的每个值先减去µ再除以σ得到标准化后的每个特征值。对于缺
失的特征值，我们将其**替换成该特征的均值**
```python
numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index
all_features[numeric_features] = all_features[numeric_features].apply(
lambda x: (x - x.mean()) / (x.std()))
# 标准化后，每个特征的均值变为0，所以可以直接⽤0来替换缺失值
all_features[numeric_features] = all_features[numeric_features].fillna(0)
#fillna用来填充空白值的方法
```
将 离 散 数 值 转 成 指 ⽰ 特 征。 举 个 例 ⼦， 假 设 特 征MSZoning⾥ ⾯ 有 两 个
不 同 的 离 散 值RL和RM， 那 么 这 ⼀ 步 转 换 将 去 掉MSZoning特 征， 并 新 加 两 个 特
征MSZoning_RL和MSZoning_RM， 其 值 为0或1。 如 果 ⼀ 个 样 本 原 来 在MSZoning⾥ 的 值
为RL，那么有MSZoning_RL=1且MSZoning_RM=0。

```
# dummy_na=True将缺失值也当作合法的特征值并为其创建指⽰特征
all_features = pd.get_dummies(all_features, dummy_na=True)
#get_dummies利用pandas实现one hot encode的方式（编码方式还需要多多了解下）
all_features.shape
```
最后，通过values属性得到NumPy格式的数据，并转成NDArray⽅便后⾯的训练

```
n_train = train_data.shape[0]
train_features = nd.array(all_features[:n_train].values)
test_features = nd.array(all_features[n_train:].values)
train_labels = nd.array(train_data.SalePrice.values).reshape((-1, 1))
```
4. 训练模型
使⽤⼀个基本的线性回归模型和平⽅损失函数来训练模型  
关键词：**对数均方误差，adam优化算法，k折交叉验证**

```
# 定义对数均方根误差
def log_rmse(net, features, labels):
    # 将⼩于1的值设成1，使得取对数时数值更稳定
    clipped_preds = nd.clip(net(features), 1, float('inf'))
    rmse = nd.sqrt(2 * loss(clipped_preds.log(), labels.log()).mean())
    return rmse.asscalar()

# 此处使用了Adam优化算法来训练模型
def train(net, train_features, train_labels, test_features, test_labels,
num_epochs, learning_rate, weight_decay, batch_size):
    train_ls, test_ls = [], []
    train_iter = gdata.DataLoader(gdata.ArrayDataset(
    train_features, train_labels), batch_size, shuffle=True)
    # 这⾥使⽤了Adam优化算法
    trainer = gluon.Trainer(net.collect_params(), 'adam', {
    'learning_rate': learning_rate, 'wd': weight_decay})
    for epoch in range(num_epochs):
        for X, y in train_iter:
            with autograd.record():
                l = loss(net(X), y)
            l.backward()
            trainer.step(batch_size)
        train_ls.append(log_rmse(net, train_features, train_labels))
    if test_labels is not None:
        test_ls.append(log_rmse(net, test_features, test_labels))
    return train_ls, test_ls
# 定义k折交叉验证
def get_k_fold_data(k, i, X, y):
    assert k > 1
    fold_size = X.shape[0] // k
    X_train, y_train = None, None
    for j in range(k):
        idx = slice(j * fold_size, (j + 1) * fold_size)
        X_part, y_part = X[idx, :], y[idx]
        if j == i:
            X_valid, y_valid = X_part, y_part
        elif X_train is None:
            X_train, y_train = X_part, y_part
        else:
            X_train = nd.concat(X_train, X_part, dim=0)
        y_train = nd.concat(y_train, y_part, dim=0)
    return X_train, y_train, X_valid, y_valid
```
5. 预测结果

```
def train_and_pred(train_features, test_features, train_labels, test_data,
num_epochs, lr, weight_decay, batch_size):
    net = get_net()
    train_ls, _ = train(net, train_features, train_labels, None, None,
                        num_epochs, lr, weight_decay, batch_size)
    # d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse')
    print('train rmse %f' % train_ls[-1])
    preds = net(test_features).asnumpy()
    test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0])
    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)
    submission.to_csv('submission.csv', index=False)

train_and_pred(train_features, test_features, train_labels, test_data,
              num_epochs, lr, weight_decay, batch_size)
```
最后将生成的submission.csv⽂件上传即可
